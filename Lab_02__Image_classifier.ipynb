{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "172bb996",
      "metadata": {
        "id": "172bb996"
      },
      "source": [
        "# **Lab 02:** Creating your own CNN with PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c203f915",
      "metadata": {
        "id": "c203f915"
      },
      "source": [
        "### **General Instructions**\n",
        "\n",
        "- In this lab, you'll create your own CNN in order to surpass an accuracy of 70% on CIFAR-10.\n",
        "\n",
        "### **System Diagram Requirement**\n",
        "\n",
        "You must include a **diagram of your system pipeline** showing the CNN architecture.\n",
        "\n",
        "This diagram is **required** to understand your model logic.\n",
        "\n",
        "You can draw it digitally, use any Pyhton library, or by hand and include an image.\n",
        "\n",
        "If your diagram was created assisted by GenAI, also include the `promt` used in the next block. If the generated system diagram is not clear or you cannot interpret it, adjust the prompt as needed or draw it by hand."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23643d66",
      "metadata": {
        "id": "23643d66"
      },
      "source": [
        "Genera un diagrama detallado de la arquitectura CNN para CIFAR-10 mediante el uso de Graphviz, mostrando todo el flujo del sistema."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7062afb",
      "metadata": {
        "id": "b7062afb"
      },
      "source": [
        "### **Load the CIFAR-10 dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "7f7771a2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7f7771a2",
        "outputId": "3d5cff63-dd32-40b5-eb4b-b5fa3751714d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:01<00:00, 98.6MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['airplane',\n",
              " 'automobile',\n",
              " 'bird',\n",
              " 'cat',\n",
              " 'deer',\n",
              " 'dog',\n",
              " 'frog',\n",
              " 'horse',\n",
              " 'ship',\n",
              " 'truck']"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# Load the CIFAR-10 dataset here\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                             download=True, transform=transform)\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                            download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "classes = train_dataset.classes\n",
        "classes"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a2f359a",
      "metadata": {
        "id": "4a2f359a"
      },
      "source": [
        "### **Create your CNN with PyTorch and train it on the CIFAR-10 dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "feea2220",
      "metadata": {
        "id": "feea2220"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch\n",
        "\n",
        "# Create your own CNN using PyTorch and train it on the CIFAR-10 dataset\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1) # Input channels = 3 (RGB), output channels = 16, kernel size = 3\n",
        "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1) # Input channels = 16, output channels = 32, kernel size = 3\n",
        "        self.pool = nn.MaxPool2d(2, 2) # Kernel size = 2, stride = 2\n",
        "        self.fc1 = nn.Linear(32 * 8 * 8, 128) # Input features = 32*8*8, output features = 128\n",
        "        self.fc2 = nn.Linear(128, 10) # Input features = 128, output features = 10 (number of classes)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.relu(self.conv1(x)))\n",
        "        x = self.pool(self.relu(self.conv2(x)))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = SimpleCNN().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "S6cxfJlvN-qZ"
      },
      "id": "S6cxfJlvN-qZ",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRyv1L9LOQwt",
        "outputId": "e03056a0-bcf7-4573-9460-6af9b2d9901f"
      },
      "id": "DRyv1L9LOQwt",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 1.5875\n",
            "Epoch 2/5, Loss: 1.2379\n",
            "Epoch 3/5, Loss: 1.1013\n",
            "Epoch 4/5, Loss: 1.0053\n",
            "Epoch 5/5, Loss: 0.9257\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "model.eval()\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs = inputs.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "        all_preds.extend(predicted.cpu().numpy())\n",
        "        all_labels.extend(labels.numpy())\n",
        "\n",
        "cnn_acc = accuracy_score(all_labels, all_preds)\n",
        "print(\"CNN Accuracy:\", cnn_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juytM-Q5OUKW",
        "outputId": "9b0208bf-e4fa-40b0-bc45-dd4e2856598b"
      },
      "id": "juytM-Q5OUKW",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN Accuracy: 0.6482\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "class AdvancedCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(AdvancedCNN, self).__init__()\n",
        "\n",
        "        # ===== BLOCK 1 =====\n",
        "        self.block1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.MaxPool2d(2)   # 32x32 → 16x16\n",
        "        )\n",
        "\n",
        "        # ===== BLOCK 2 =====\n",
        "        self.block2 = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.MaxPool2d(2)   # 16x16 → 8x8\n",
        "        )\n",
        "\n",
        "        # ===== BLOCK 3 =====\n",
        "        self.block3 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.MaxPool2d(2)   # 8x8 → 4x4\n",
        "        )\n",
        "\n",
        "        # ===== CLASSIFIER =====\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "\n",
        "            nn.Linear(128 * 4 * 4, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "\n",
        "            nn.Linear(256, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.block1(x)\n",
        "        x = self.block2(x)\n",
        "        x = self.block3(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# ===== TRAINING SETUP =====\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = AdvancedCNN().to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "UyvCrWZ0PzIn"
      },
      "id": "UyvCrWZ0PzIn",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "5907ce4d",
      "metadata": {
        "id": "5907ce4d"
      },
      "source": [
        "### **Evaluate the accuracy of your CNN (must be >= 70%)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "7014732a",
      "metadata": {
        "id": "7014732a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9448e882-48fc-4441-963b-9b180515efc5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Loss: 1.4888\n",
            "Epoch [2/5], Loss: 1.0489\n",
            "Epoch [3/5], Loss: 0.8563\n",
            "Epoch [4/5], Loss: 0.7421\n",
            "Epoch [5/5], Loss: 0.6517\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the accuracy of your CNN (must be >= 70%)\n",
        "num_epochs = 5\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        # Reset gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backprop\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f\"Test Accuracy: {accuracy:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBPMY1OrQMTt",
        "outputId": "cdd28425-98d0-48b8-deb2-01a685248d22"
      },
      "id": "kBPMY1OrQMTt",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 76.20%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "637323c3",
      "metadata": {
        "id": "637323c3"
      },
      "source": [
        "### **System Diagram**\n",
        "\n",
        "Insert your system diagram below (image or drawing). It must clearly show:\n",
        "\n",
        "- Number of convolutional layers  \n",
        "- Kernel size(s)\n",
        "- Pooling layers (if any)  \n",
        "- etc..  "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import graphviz\n",
        "\n",
        "dot_code = '''\n",
        "digraph CNN_CIFAR10 {\n",
        "\n",
        "rankdir=TB;\n",
        "splines=ortho;\n",
        "nodesep=0.6;\n",
        "ranksep=1.0;\n",
        "\n",
        "node [shape=box, style=filled, fontname=\"Helvetica\"];\n",
        "\n",
        "# INPUT\n",
        "input [label=\"CIFAR-10\\n3x32x32\", fillcolor=\"#A5D6A7\"];\n",
        "\n",
        "# BLOCK 1\n",
        "subgraph cluster1 {\n",
        "    label=\"Conv Block 1\";\n",
        "    style=rounded;\n",
        "\n",
        "    conv1 [label=\"Conv 3→32\", fillcolor=\"#90CAF9\"];\n",
        "    conv2 [label=\"Conv 32→32\", fillcolor=\"#90CAF9\"];\n",
        "    pool1 [label=\"MaxPool\\n32x16x16\", fillcolor=\"#FFCC80\"];\n",
        "}\n",
        "\n",
        "# BLOCK 2\n",
        "subgraph cluster2 {\n",
        "    label=\"Conv Block 2\";\n",
        "    style=rounded;\n",
        "\n",
        "    conv3 [label=\"Conv 32→64\", fillcolor=\"#64B5F6\"];\n",
        "    conv4 [label=\"Conv 64→64\", fillcolor=\"#64B5F6\"];\n",
        "    pool2 [label=\"MaxPool\\n64x8x8\", fillcolor=\"#FFCC80\"];\n",
        "}\n",
        "\n",
        "# BLOCK 3\n",
        "subgraph cluster3 {\n",
        "    label=\"Conv Block 3\";\n",
        "    style=rounded;\n",
        "\n",
        "    conv5 [label=\"Conv 64→128\", fillcolor=\"#42A5F5\"];\n",
        "    conv6 [label=\"Conv 128→128\", fillcolor=\"#42A5F5\"];\n",
        "    pool3 [label=\"MaxPool\\n128x4x4\", fillcolor=\"#FFCC80\"];\n",
        "}\n",
        "\n",
        "# CLASSIFIER\n",
        "subgraph cluster4 {\n",
        "    label=\"Classifier\";\n",
        "    style=rounded;\n",
        "\n",
        "    flatten [label=\"Flatten\\n2048\", fillcolor=\"#FFF59D\"];\n",
        "    fc1 [label=\"FC 512\", fillcolor=\"#CE93D8\"];\n",
        "    fc2 [label=\"FC 256\", fillcolor=\"#CE93D8\"];\n",
        "    fc3 [label=\"FC 10\", fillcolor=\"#F48FB1\"];\n",
        "}\n",
        "\n",
        "output [label=\"Softmax\\nClasses\", fillcolor=\"#A5D6A7\"];\n",
        "\n",
        "# FLOW\n",
        "input -> conv1 -> conv2 -> pool1;\n",
        "pool1 -> conv3 -> conv4 -> pool2;\n",
        "pool2 -> conv5 -> conv6 -> pool3;\n",
        "pool3 -> flatten -> fc1 -> fc2 -> fc3 -> output;\n",
        "\n",
        "}\n",
        "'''\n",
        "\n",
        "graph = graphviz.Source(dot_code)\n",
        "graph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6GN5ck1WbxBC",
        "outputId": "d092cbde-31e9-4b74-be37-9689aa5b0a32"
      },
      "id": "6GN5ck1WbxBC",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: CNN_CIFAR10 Pages: 1 -->\n<svg width=\"150pt\" height=\"1568pt\"\n viewBox=\"0.00 0.00 150.00 1568.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 1564)\">\n<title>CNN_CIFAR10</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-1564 146,-1564 146,4 -4,4\"/>\n<g id=\"clust1\" class=\"cluster\">\n<title>cluster1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M27,-1188C27,-1188 115,-1188 115,-1188 121,-1188 127,-1194 127,-1200 127,-1200 127,-1469 127,-1469 127,-1475 121,-1481 115,-1481 115,-1481 27,-1481 27,-1481 21,-1481 15,-1475 15,-1469 15,-1469 15,-1200 15,-1200 15,-1194 21,-1188 27,-1188\"/>\n<text text-anchor=\"middle\" x=\"71\" y=\"-1465.8\" font-family=\"Times,serif\" font-size=\"14.00\">Conv Block 1</text>\n</g>\n<g id=\"clust2\" class=\"cluster\">\n<title>cluster2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M27,-862C27,-862 115,-862 115,-862 121,-862 127,-868 127,-874 127,-874 127,-1143 127,-1143 127,-1149 121,-1155 115,-1155 115,-1155 27,-1155 27,-1155 21,-1155 15,-1149 15,-1143 15,-1143 15,-874 15,-874 15,-868 21,-862 27,-862\"/>\n<text text-anchor=\"middle\" x=\"71\" y=\"-1139.8\" font-family=\"Times,serif\" font-size=\"14.00\">Conv Block 2</text>\n</g>\n<g id=\"clust3\" class=\"cluster\">\n<title>cluster3</title>\n<path fill=\"none\" stroke=\"black\" d=\"M20,-536C20,-536 122,-536 122,-536 128,-536 134,-542 134,-548 134,-548 134,-817 134,-817 134,-823 128,-829 122,-829 122,-829 20,-829 20,-829 14,-829 8,-823 8,-817 8,-817 8,-548 8,-548 8,-542 14,-536 20,-536\"/>\n<text text-anchor=\"middle\" x=\"71\" y=\"-813.8\" font-family=\"Times,serif\" font-size=\"14.00\">Conv Block 3</text>\n</g>\n<g id=\"clust4\" class=\"cluster\">\n<title>cluster4</title>\n<path fill=\"none\" stroke=\"black\" d=\"M44,-102C44,-102 98,-102 98,-102 104,-102 110,-108 110,-114 110,-114 110,-491 110,-491 110,-497 104,-503 98,-503 98,-503 44,-503 44,-503 38,-503 32,-497 32,-491 32,-491 32,-114 32,-114 32,-108 38,-102 44,-102\"/>\n<text text-anchor=\"middle\" x=\"71\" y=\"-487.8\" font-family=\"Times,serif\" font-size=\"14.00\">Classifier</text>\n</g>\n<!-- input -->\n<g id=\"node1\" class=\"node\">\n<title>input</title>\n<polygon fill=\"#a5d6a7\" stroke=\"black\" points=\"109,-1560 33,-1560 33,-1522 109,-1522 109,-1560\"/>\n<text text-anchor=\"middle\" x=\"71\" y=\"-1544.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">CIFAR&#45;10</text>\n<text text-anchor=\"middle\" x=\"71\" y=\"-1529.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">3x32x32</text>\n</g>\n<!-- conv1 -->\n<g id=\"node2\" class=\"node\">\n<title>conv1</title>\n<polygon fill=\"#90caf9\" stroke=\"black\" points=\"115.5,-1450 26.5,-1450 26.5,-1414 115.5,-1414 115.5,-1450\"/>\n<text text-anchor=\"middle\" x=\"71\" y=\"-1428.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Conv 3→32</text>\n</g>\n<!-- input&#45;&gt;conv1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>input&#45;&gt;conv1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M71,-1521.76C71,-1521.76 71,-1460.32 71,-1460.32\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"74.5,-1460.32 71,-1450.32 67.5,-1460.32 74.5,-1460.32\"/>\n</g>\n<!-- conv2 -->\n<g id=\"node3\" class=\"node\">\n<title>conv2</title>\n<polygon fill=\"#90caf9\" stroke=\"black\" points=\"119,-1342 23,-1342 23,-1306 119,-1306 119,-1342\"/>\n<text text-anchor=\"middle\" x=\"71\" y=\"-1320.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Conv 32→32</text>\n</g>\n<!-- conv1&#45;&gt;conv2 -->\n<g id=\"edge2\" class=\"edge\">\n<title>conv1&#45;&gt;conv2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M71,-1413.68C71,-1413.68 71,-1352.05 71,-1352.05\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"74.5,-1352.05 71,-1342.05 67.5,-1352.05 74.5,-1352.05\"/>\n</g>\n<!-- pool1 -->\n<g id=\"node4\" class=\"node\">\n<title>pool1</title>\n<polygon fill=\"#ffcc80\" stroke=\"black\" points=\"108.5,-1234 33.5,-1234 33.5,-1196 108.5,-1196 108.5,-1234\"/>\n<text text-anchor=\"middle\" x=\"71\" y=\"-1218.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">MaxPool</text>\n<text text-anchor=\"middle\" x=\"71\" y=\"-1203.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">32x16x16</text>\n</g>\n<!-- conv2&#45;&gt;pool1 -->\n<g id=\"edge3\" class=\"edge\">\n<title>conv2&#45;&gt;pool1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M71,-1305.51C71,-1305.51 71,-1244.32 71,-1244.32\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"74.5,-1244.32 71,-1234.32 67.5,-1244.32 74.5,-1244.32\"/>\n</g>\n<!-- conv3 -->\n<g id=\"node5\" class=\"node\">\n<title>conv3</title>\n<polygon fill=\"#64b5f6\" stroke=\"black\" points=\"119,-1124 23,-1124 23,-1088 119,-1088 119,-1124\"/>\n<text text-anchor=\"middle\" x=\"71\" y=\"-1102.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Conv 32→64</text>\n</g>\n<!-- pool1&#45;&gt;conv3 -->\n<g id=\"edge4\" class=\"edge\">\n<title>pool1&#45;&gt;conv3</title>\n<path fill=\"none\" stroke=\"black\" d=\"M71,-1195.76C71,-1195.76 71,-1134.32 71,-1134.32\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"74.5,-1134.32 71,-1124.32 67.5,-1134.32 74.5,-1134.32\"/>\n</g>\n<!-- conv4 -->\n<g id=\"node6\" class=\"node\">\n<title>conv4</title>\n<polygon fill=\"#64b5f6\" stroke=\"black\" points=\"119,-1016 23,-1016 23,-980 119,-980 119,-1016\"/>\n<text text-anchor=\"middle\" x=\"71\" y=\"-994.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Conv 64→64</text>\n</g>\n<!-- conv3&#45;&gt;conv4 -->\n<g id=\"edge5\" class=\"edge\">\n<title>conv3&#45;&gt;conv4</title>\n<path fill=\"none\" stroke=\"black\" d=\"M71,-1087.68C71,-1087.68 71,-1026.05 71,-1026.05\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"74.5,-1026.05 71,-1016.05 67.5,-1026.05 74.5,-1026.05\"/>\n</g>\n<!-- pool2 -->\n<g id=\"node7\" class=\"node\">\n<title>pool2</title>\n<polygon fill=\"#ffcc80\" stroke=\"black\" points=\"106,-908 36,-908 36,-870 106,-870 106,-908\"/>\n<text text-anchor=\"middle\" x=\"71\" y=\"-892.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">MaxPool</text>\n<text text-anchor=\"middle\" x=\"71\" y=\"-877.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">64x8x8</text>\n</g>\n<!-- conv4&#45;&gt;pool2 -->\n<g id=\"edge6\" class=\"edge\">\n<title>conv4&#45;&gt;pool2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M71,-979.51C71,-979.51 71,-918.32 71,-918.32\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"74.5,-918.32 71,-908.32 67.5,-918.32 74.5,-918.32\"/>\n</g>\n<!-- conv5 -->\n<g id=\"node8\" class=\"node\">\n<title>conv5</title>\n<polygon fill=\"#42a5f5\" stroke=\"black\" points=\"123,-798 19,-798 19,-762 123,-762 123,-798\"/>\n<text text-anchor=\"middle\" x=\"71\" y=\"-776.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Conv 64→128</text>\n</g>\n<!-- pool2&#45;&gt;conv5 -->\n<g id=\"edge7\" class=\"edge\">\n<title>pool2&#45;&gt;conv5</title>\n<path fill=\"none\" stroke=\"black\" d=\"M71,-869.76C71,-869.76 71,-808.32 71,-808.32\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"74.5,-808.32 71,-798.32 67.5,-808.32 74.5,-808.32\"/>\n</g>\n<!-- conv6 -->\n<g id=\"node9\" class=\"node\">\n<title>conv6</title>\n<polygon fill=\"#42a5f5\" stroke=\"black\" points=\"126.5,-690 15.5,-690 15.5,-654 126.5,-654 126.5,-690\"/>\n<text text-anchor=\"middle\" x=\"71\" y=\"-668.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Conv 128→128</text>\n</g>\n<!-- conv5&#45;&gt;conv6 -->\n<g id=\"edge8\" class=\"edge\">\n<title>conv5&#45;&gt;conv6</title>\n<path fill=\"none\" stroke=\"black\" d=\"M71,-761.68C71,-761.68 71,-700.05 71,-700.05\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"74.5,-700.05 71,-690.05 67.5,-700.05 74.5,-700.05\"/>\n</g>\n<!-- pool3 -->\n<g id=\"node10\" class=\"node\">\n<title>pool3</title>\n<polygon fill=\"#ffcc80\" stroke=\"black\" points=\"106,-582 36,-582 36,-544 106,-544 106,-582\"/>\n<text text-anchor=\"middle\" x=\"71\" y=\"-566.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">MaxPool</text>\n<text text-anchor=\"middle\" x=\"71\" y=\"-551.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">128x4x4</text>\n</g>\n<!-- conv6&#45;&gt;pool3 -->\n<g id=\"edge9\" class=\"edge\">\n<title>conv6&#45;&gt;pool3</title>\n<path fill=\"none\" stroke=\"black\" d=\"M71,-653.51C71,-653.51 71,-592.32 71,-592.32\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"74.5,-592.32 71,-582.32 67.5,-592.32 74.5,-592.32\"/>\n</g>\n<!-- flatten -->\n<g id=\"node11\" class=\"node\">\n<title>flatten</title>\n<polygon fill=\"#fff59d\" stroke=\"black\" points=\"100,-472 42,-472 42,-434 100,-434 100,-472\"/>\n<text text-anchor=\"middle\" x=\"71\" y=\"-456.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Flatten</text>\n<text text-anchor=\"middle\" x=\"71\" y=\"-441.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">2048</text>\n</g>\n<!-- pool3&#45;&gt;flatten -->\n<g id=\"edge10\" class=\"edge\">\n<title>pool3&#45;&gt;flatten</title>\n<path fill=\"none\" stroke=\"black\" d=\"M71,-543.84C71,-543.84 71,-482.31 71,-482.31\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"74.5,-482.31 71,-472.31 67.5,-482.31 74.5,-482.31\"/>\n</g>\n<!-- fc1 -->\n<g id=\"node12\" class=\"node\">\n<title>fc1</title>\n<polygon fill=\"#ce93d8\" stroke=\"black\" points=\"101.5,-362 40.5,-362 40.5,-326 101.5,-326 101.5,-362\"/>\n<text text-anchor=\"middle\" x=\"71\" y=\"-340.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">FC 512</text>\n</g>\n<!-- flatten&#45;&gt;fc1 -->\n<g id=\"edge11\" class=\"edge\">\n<title>flatten&#45;&gt;fc1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M71,-433.76C71,-433.76 71,-372.32 71,-372.32\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"74.5,-372.32 71,-362.32 67.5,-372.32 74.5,-372.32\"/>\n</g>\n<!-- fc2 -->\n<g id=\"node13\" class=\"node\">\n<title>fc2</title>\n<polygon fill=\"#ce93d8\" stroke=\"black\" points=\"101.5,-254 40.5,-254 40.5,-218 101.5,-218 101.5,-254\"/>\n<text text-anchor=\"middle\" x=\"71\" y=\"-232.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">FC 256</text>\n</g>\n<!-- fc1&#45;&gt;fc2 -->\n<g id=\"edge12\" class=\"edge\">\n<title>fc1&#45;&gt;fc2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M71,-325.68C71,-325.68 71,-264.05 71,-264.05\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"74.5,-264.05 71,-254.05 67.5,-264.05 74.5,-264.05\"/>\n</g>\n<!-- fc3 -->\n<g id=\"node14\" class=\"node\">\n<title>fc3</title>\n<polygon fill=\"#f48fb1\" stroke=\"black\" points=\"98,-146 44,-146 44,-110 98,-110 98,-146\"/>\n<text text-anchor=\"middle\" x=\"71\" y=\"-124.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">FC 10</text>\n</g>\n<!-- fc2&#45;&gt;fc3 -->\n<g id=\"edge13\" class=\"edge\">\n<title>fc2&#45;&gt;fc3</title>\n<path fill=\"none\" stroke=\"black\" d=\"M71,-217.68C71,-217.68 71,-156.05 71,-156.05\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"74.5,-156.05 71,-146.05 67.5,-156.05 74.5,-156.05\"/>\n</g>\n<!-- output -->\n<g id=\"node15\" class=\"node\">\n<title>output</title>\n<polygon fill=\"#a5d6a7\" stroke=\"black\" points=\"104.5,-38 37.5,-38 37.5,0 104.5,0 104.5,-38\"/>\n<text text-anchor=\"middle\" x=\"71\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Softmax</text>\n<text text-anchor=\"middle\" x=\"71\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Classes</text>\n</g>\n<!-- fc3&#45;&gt;output -->\n<g id=\"edge14\" class=\"edge\">\n<title>fc3&#45;&gt;output</title>\n<path fill=\"none\" stroke=\"black\" d=\"M71,-109.51C71,-109.51 71,-48.32 71,-48.32\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"74.5,-48.32 71,-38.32 67.5,-48.32 74.5,-48.32\"/>\n</g>\n</g>\n</svg>\n",
            "text/plain": [
              "<graphviz.sources.Source at 0x7d0ea4383830>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4593b8b4",
      "metadata": {
        "id": "4593b8b4"
      },
      "source": [
        "### **Written Analysis Questions**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88a80f22",
      "metadata": {
        "id": "88a80f22"
      },
      "source": [
        "**1. Why increasing depth could improve performance.**\n",
        "\n",
        "Increasing depth allows the network to learn a feature hierarchy. Early layers capture low-level features like edges and textures, while deeper layers compose these into high-level abstractions and complex object parts\n",
        "\n",
        "**2. Under what conditions deeper networks may hurt performance.**\n",
        "\n",
        "Deep networks can suffer from the vanishing gradient problem, where error signals become too small during backpropagation to update the initial layers. Furthermore, if the network is too deep for the complexity of the data, it may lead to \"degradation,\" where accuracy plateaus or decreases, and it becomes significantly more prone to overfitting on the training set\n",
        "\n",
        "**3. How could dropout, batch normalization, or data augmentation help?**\n",
        "\n",
        "Batch Normalization: Stabilizes training by normalizing layer inputs, allowing for higher learning rates and faster convergence.\n",
        "**4. How would you determine whether your CNN is overfitting or underfitting?**\n",
        "\n",
        "I would compare the training and validation/test accuracy curves. Overfitting is identified when training accuracy is very high but test accuracy is significantly lower or begins to drop. Underfitting occurs when both training and test accuracies remain low, suggesting the model is not complex enough to capture the data patterns.\n",
        "\n",
        "**5. Which architectural components most impact computational cost?**\n",
        "\n",
        "The Convolutional Layers (specifically those with a high number of filters and large kernel sizes) consume the most FLOPs (floating-point operations) during the forward and backward pass. Additionally, the first Fully Connected (Dense) layer after flattening usually contains the vast majority of the model's total parameters.\n",
        "\n",
        "**6. Whether the accuracy gain justifies the added complexity in a real-world deployment scenario.**\n",
        "\n",
        "This depends on the application context:\n",
        "In high-stakes domains (medical imaging, autonomous driving, fraud detection), even small accuracy improvements can justify increased complexity.\n",
        "In resource-constrained environments (mobile devices, embedded systems), simpler models may be preferred due to lower latency and energy consumption."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec40513c",
      "metadata": {
        "id": "ec40513c"
      },
      "source": [
        "## **Grading Rubric (10 points)**\n",
        "\n",
        "| Criterion | Points |\n",
        "|------------|--------|\n",
        "| **Baseline Reproduction** – Correct implementation and training of the provided baseline CNN. Clear report of baseline accuracy and training setup. | 1 |\n",
        "| **Architectural Modifications** – Meaningful and technically justified changes to the CNN architecture (e.g., depth, kernel size, normalization, dropout, residual connections). Changes must go beyond trivial parameter tuning. | 2 |\n",
        "| **Written Architectural Justification** – Clear explanation of *why* the chosen modifications should improve performance (receptive field, feature hierarchy, regularization, gradient flow, etc.). | 2 |\n",
        "| **Experimental Design & Comparison** – Systematic comparison between baseline and modified model (same dataset split, controlled variables, reported metrics). Includes training/validation accuracy curves. | 2 |\n",
        "| **Performance Improvement** – Modified architecture surpasses baseline validation/test accuracy. <br>• +1% improvement: 0.5 pts <br>• +2% improvement: 1 pt | 1 |\n",
        "| **Generalization Analysis** – Discussion of overfitting/underfitting behavior and the role of regularization techniques (BatchNorm, Dropout, data augmentation, etc.). | 1 |\n",
        "| **Computational Tradeoff Reflection** – Analysis of parameter count, training time, and whether the accuracy gain justifies the added complexity. | 1 |\n",
        "| **Code Clarity & PyTorch Best Practices** – Clean modular implementation (proper use of `nn.Module`, readable forward pass, reproducibility practices). | 1 |\n",
        "| **Total** | **10** |\n",
        "\n",
        "---\n",
        "\n",
        "### Notes\n",
        "\n",
        "- Simply increasing the number of filters without justification will not receive full architectural credit.\n",
        "- Accuracy alone does not guarantee a high grade — reasoning and analysis are weighted heavily.\n",
        "- Extra credit (+0.5) may be awarded for implementing advanced concepts (e.g., residual blocks, learning rate scheduling experiments, or ablation studies). Applies just for students with <10 points."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8222ad2",
      "metadata": {
        "id": "b8222ad2"
      },
      "source": [
        "---\n",
        "\n",
        "<p style=\"text-align: right; font-size:14px; color:gray;\">\n",
        "<b>Prepared by:</b><br>\n",
        "Manuel Eugenio Morocho-Cayamcela\n",
        "</p>"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}